{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEe1ln316KZw",
    "outputId": "a0e108e3-3b0b-45d5-818b-1f6ea389dbf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '2021_hackaton_material'...\n",
      "remote: Enumerating objects: 21, done.\u001b[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 21 (delta 6), reused 14 (delta 3), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (21/21), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/TheBrainCodeGames/2021_hackaton_material\n",
    "!mv 2021_hackaton_material/bcg_auxiliary.py ./bcg_auxiliary.py\n",
    "!mv 2021_hackaton_material/bz_LoadBinary.py ./bz_LoadBinary.py\n",
    "!rm -r 2021_hackaton_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C2QX_rW-KGsX"
   },
   "outputs": [],
   "source": [
    "from bcg_auxiliary import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkxDdX3W5JaW"
   },
   "source": [
    "# Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sTCBSeN5G1m",
    "outputId": "1cefd757-116b-429b-f0b4-bb7973e29ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'figshare'...\n",
      "remote: Enumerating objects: 53, done.\u001b[K\n",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 53 (delta 6), reused 9 (delta 1), pack-reused 35\u001b[K\n",
      "Unpacking objects: 100% (53/53), done.\n",
      "/content/figshare\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating figshare.egg-info\n",
      "writing figshare.egg-info/PKG-INFO\n",
      "writing dependency_links to figshare.egg-info/dependency_links.txt\n",
      "writing requirements to figshare.egg-info/requires.txt\n",
      "writing top-level names to figshare.egg-info/top_level.txt\n",
      "writing manifest file 'figshare.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE.md'\n",
      "writing manifest file 'figshare.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/figshare\n",
      "copying figshare/figshare.py -> build/lib/figshare\n",
      "copying figshare/__init__.py -> build/lib/figshare\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/figshare\n",
      "copying build/lib/figshare/figshare.py -> build/bdist.linux-x86_64/egg/figshare\n",
      "copying build/lib/figshare/__init__.py -> build/bdist.linux-x86_64/egg/figshare\n",
      "byte-compiling build/bdist.linux-x86_64/egg/figshare/figshare.py to figshare.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/figshare/__init__.py to __init__.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying figshare.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying figshare.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying figshare.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying figshare.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying figshare.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating dist\n",
      "creating 'dist/figshare-0.1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing figshare-0.1.0-py3.7.egg\n",
      "Copying figshare-0.1.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding figshare 0.1.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/figshare-0.1.0-py3.7.egg\n",
      "Processing dependencies for figshare==0.1.0\n",
      "Searching for pytest==3.0.4\n",
      "Reading https://pypi.org/simple/pytest/\n",
      "Downloading https://files.pythonhosted.org/packages/10/5b/91cadc7c1b82ae287a50e0d5a2ebc17d8ba60cf6b9e0b5df6f9ad4608d85/pytest-3.0.4-py2.py3-none-any.whl#sha256=f043cb1eaafc9a10c9de77a7d57ba9ccb1d919edb45926b83c29e2482a41101e\n",
      "Best match: pytest 3.0.4\n",
      "Processing pytest-3.0.4-py2.py3-none-any.whl\n",
      "Installing pytest-3.0.4-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding pytest 3.0.4 to easy-install.pth file\n",
      "Installing py.test script to /usr/local/bin\n",
      "Installing pytest script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/pytest-3.0.4-py3.7.egg\n",
      "Searching for requests==2.20.0\n",
      "Reading https://pypi.org/simple/requests/\n",
      "Downloading https://files.pythonhosted.org/packages/f1/ca/10332a30cb25b627192b4ea272c351bce3ca1091e541245cccbace6051d8/requests-2.20.0-py2.py3-none-any.whl#sha256=a84b8c9ab6239b578f22d1c21d51b696dcfe004032bb80ea832398d6909d7279\n",
      "Best match: requests 2.20.0\n",
      "Processing requests-2.20.0-py2.py3-none-any.whl\n",
      "Installing requests-2.20.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding requests 2.20.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/requests-2.20.0-py3.7.egg\n",
      "Searching for idna<2.8,>=2.5\n",
      "Reading https://pypi.org/simple/idna/\n",
      "Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl#sha256=156a6814fb5ac1fc6850fb002e0852d56c0c8d2531923a51032d1b70760e186e\n",
      "Best match: idna 2.7\n",
      "Processing idna-2.7-py2.py3-none-any.whl\n",
      "Installing idna-2.7-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding idna 2.7 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/idna-2.7-py3.7.egg\n",
      "Searching for py==1.10.0\n",
      "Best match: py 1.10.0\n",
      "Adding py 1.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for urllib3==1.24.3\n",
      "Best match: urllib3 1.24.3\n",
      "Adding urllib3 1.24.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for chardet==3.0.4\n",
      "Best match: chardet 3.0.4\n",
      "Adding chardet 3.0.4 to easy-install.pth file\n",
      "Installing chardetect script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for certifi==2021.5.30\n",
      "Best match: certifi 2021.5.30\n",
      "Adding certifi 2021.5.30 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Finished processing dependencies for figshare==0.1.0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cognoma/figshare.git\n",
    "%cd /content/figshare\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_-HM-CFK5IF2"
   },
   "outputs": [],
   "source": [
    "from figshare.figshare import Figshare\n",
    "fs = Figshare()\n",
    "fs.retrieve_files_from_article(16847521, directory=\"/content/Datos/Entrenamiento/Amigo2\")\n",
    "fs.retrieve_files_from_article(16856137, directory=\"/content/Datos/Entrenamiento/Som2\")\n",
    "fs.retrieve_files_from_article(14959449, directory=\"/content/Datos/Validacion/Dlx1\")\n",
    "fs.retrieve_files_from_article(14960085, directory=\"/content/Datos/Validacion/Thy7\")\n",
    "fs.retrieve_files_from_article(16856182, directory=\"/content/Datos/Test/Test1\")\n",
    "fs.retrieve_files_from_article(16856248, directory=\"/content/Datos/Test/Test2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nq6ZCfZxKGsc"
   },
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5KHh4eoKGse"
   },
   "source": [
    "## Función getPendientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oEe_dKeAyVAG"
   },
   "outputs": [],
   "source": [
    "def getPendientes(canal):\n",
    "\t\"\"\"\n",
    "\tObtiene las diferencias de amplitud entre un punto y su vecino anterior y posterior\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tcanal : Numpy array (N x 1)\n",
    "\t\tNumpy array que contiene las amplitudes de un canal\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tdiffs : Numpy array (N-1 x 1)\n",
    "\t\tNumpy array  que contiene las pendientes de los puntos repsecto a sus dos vecinos\n",
    "\n",
    "\tExample\n",
    "\t-------\n",
    "\tdiffs = getPendientes(canal0)\n",
    "\t\"\"\"\n",
    "\n",
    "\tdiffs = list()\n",
    "\tfor i in range(0, len(canal) - 1):\n",
    "\t\tdiffs.append(canal[i+1] - canal[i])\n",
    "\treturn np.array(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xV-o0XPhKGsg"
   },
   "source": [
    "## Función getCharacteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TQzdo5nmy6yg"
   },
   "outputs": [],
   "source": [
    "def getCharacteristics(differences, amplitudes, intervalo=400):\n",
    "\t\"\"\"\n",
    "\tObtiene las caracteristicas de un ripple\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdifferences : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene las pendientes de los puntos \n",
    "\t\trespecto a sus dos vecinos\n",
    "\tamplitudes :  Numpy Array (N x 1)\n",
    "\t\tNumpy array que contiene las amplitudes de un canal\n",
    "\tintervalo : int\n",
    "\t\tTamaño de los intervalos en los que se dividira la senal\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tsumsPend : Numpy Array (N - intervalo x 1)\n",
    "\t\tNumpy array  que contiene la suma de las pendientes de los \n",
    "\t\tpuntos dentro de un intervalo\n",
    "\tsumsAmpl : Numpy Array (N - intervalo x 1)\n",
    "\t\tNumpy array  que contiene la suma de las amplitudes de los \n",
    "\t\tpuntos dentro de un intervalo\n",
    "\tsumsAbsAmpl\t: Numpy Array (N - intervalo x 1)\n",
    "\t\tNumpy array con la suma de las amplitudes en valor absoluto\n",
    "\t\tde los puntos dentro de un intervalo\n",
    "\tExample\n",
    "\t-------\n",
    "\tpendientes, amplitudes, absampl = getCharacteristics(diffs, canal, 200)\n",
    "\t\"\"\"\n",
    "\n",
    "\tabsolutes = np.abs(differences)\n",
    "\tabsamp = np.abs(amplitudes)\n",
    "\tsumsPend = list()\n",
    "\tsumsAmpl = list()\n",
    "\tsumsAbsAmpl = list()\n",
    "\n",
    "\tsumsPendInter = np.sum(absolutes[:intervalo])\n",
    "\tsumsPend.append(sumsPendInter)\n",
    "\tsumsAmplInter = np.sum(amplitudes[:intervalo])\n",
    "\tsumsAmpl.append(sumsAmplInter)\n",
    "\tsumsAbsAmplInter = np.sum(absamp[:intervalo])\n",
    "\tsumsAbsAmpl.append(sumsAbsAmplInter)\n",
    "\n",
    "\tfor i in range(1, len(absolutes) - intervalo):\n",
    "\t\tsumsPendInter = sumsPendInter + absolutes[i+intervalo] - absolutes[i-1]\n",
    "\t\tsumsPend.append(sumsPendInter)\n",
    "\t\tsumsAmplInter = sumsAmplInter + amplitudes[i+intervalo] - amplitudes[i-1]\n",
    "\t\tsumsAmpl.append(sumsAmplInter)\n",
    "\t\tsumsAbsAmplInter = sumsAbsAmplInter + absamp[i+intervalo] - absamp[i-1]\n",
    "\t\tsumsAbsAmpl.append(sumsAbsAmplInter)\n",
    "\n",
    "\treturn np.array(sumsPend), np.array(sumsAmpl), np.array(sumsAbsAmpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVrUyJtGKGsj"
   },
   "source": [
    "## Función solsToIntervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RbYK39-a4TAC"
   },
   "outputs": [],
   "source": [
    "def solsToIntervals(solutions, intervalo=400, porcentaje=0.5):\n",
    "  \"\"\"\n",
    "\tPasa el array de soluciones a intervalos\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tsolutions : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene si un punto es ripple o no\n",
    "\tintervalo : int\n",
    "\t\tTamaño de los intervalos en los que esta dividida la senal\n",
    "\tporcentaje : int\n",
    "\t\tPorcentaje del numero de 1s que debe haber en un intervalo\n",
    "\t\tpara que se considere ripple\n",
    "\t\n",
    "\tReturns\n",
    "\t-------\n",
    "\tsumsSols : Numpy Array (N - intervalo - 1 x 1)\n",
    "\t\tNumpy array  que contiene  si un intervalo\n",
    "\t\tes ripple o no\t\n",
    "\n",
    "\tExample\n",
    "\t-------\n",
    "\tsolsIntervalo = solsToIntervals(signal)\n",
    "\n",
    "\t\"\"\"\n",
    "  \n",
    "  sumsSols = list()\n",
    "\n",
    "  sumsSolsInter = np.sum(solutions[:intervalo])\n",
    "  sumsSols.append(sumsSolsInter)\n",
    "  umbral = int(porcentaje * intervalo)\n",
    "  \n",
    "  for i in range(1, len(solutions) - intervalo - 1):\n",
    "    sumsSolsInter = sumsSolsInter + solutions[i+intervalo] - solutions[i-1]\n",
    "    sol = 1 if sumsSolsInter >= umbral else 0\n",
    "    sumsSols.append(sol)\n",
    "  \n",
    "  return np.array(sumsSols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr0r-sOOKGsl"
   },
   "source": [
    "## Función getDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4To7O_Gc9t4n"
   },
   "outputs": [],
   "source": [
    "def getDataSet(pendientes, amplitudes, abs_amplitudes):\n",
    "\t\"\"\"\n",
    "\tUne las caracteristicas del ripple en un mismo array\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tpendientes : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene la suma de las pendientes de los \n",
    "\t\tpuntos dentro de un intervalo\n",
    "\tamplitudes : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene la suma de las amplitudes de los \n",
    "\t\tpuntos dentro de un intervalo\n",
    "\tabs_amplitudes : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene la suma de las amplitudes en\n",
    "\t\tvalor absoluto de los puntos dentro de un intervalo\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tdataset : Numpy Array (N x 3)\n",
    "\t\tNumpy array  que contiene los array de \n",
    "\t\tpendientes y amplitudes unidos\n",
    "\n",
    "\tExample\n",
    "\t-------\n",
    "\ttrain = getDataSet(pendientes, amplitudes, absampl)\n",
    "\t\"\"\"\n",
    "\tdataset = np.zeros([len(pendientes), 3])\n",
    "\tdataset[:, 0] = pendientes\n",
    "\tdataset[:, 1] = amplitudes\n",
    "\tdataset[:, 2] = abs_amplitudes\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWSFxtJUKGsn"
   },
   "source": [
    "## Función toTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UPku3hc2TrHb"
   },
   "outputs": [],
   "source": [
    "def toTimes(prediction, fs, zeros=400, intervalo=400) :\n",
    "  \"\"\"\n",
    "  Pasa la prediccion de los intervalos a intervalos completos de tiempo\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  prediction : Numpy Array (N x 1)\n",
    "    Numpy array que indica si un intervalo es ripple o no\n",
    "  fs : int\n",
    "    Frecuencia de sampleo\n",
    "  zeros : int\n",
    "    Numero de ceros que tiene que pasar para que se considere\n",
    "    que el ripple ha terminado\n",
    "  intervalo : int\n",
    "    Tamaño de los intervalos en los que esta dividida la senal\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  times : Numpy Array (N x 1)\n",
    "    Numpy array con las predicciones pasadas a tiempos\n",
    "\n",
    "  Example\n",
    "  -------\n",
    "  tiemposBoostPredict = toTimes(boostPredict, fs, zeros=700, intervalo=400)\n",
    "  \"\"\"\n",
    "  insideRipple = False\n",
    "  ripples = list()\n",
    "\n",
    "  start = 0\n",
    "  end = 0\n",
    "  zerosCount = 0\n",
    "  zerosUmbral = zeros\n",
    "\n",
    "  for i, n in enumerate(prediction):\n",
    "    if (n == 1):\n",
    "      if (not insideRipple):\n",
    "        insideRipple = True\n",
    "        start = i\n",
    "      zerosCount = 0\n",
    "    elif (n == 0 and insideRipple):\n",
    "      zerosCount += 1\n",
    "      if (zerosCount >= zerosUmbral):\n",
    "        end =  i - zerosUmbral\n",
    "        ripples.append(np.array([start, end]))\n",
    "        insideRipple = False\n",
    "        start, end = 0, 0\n",
    "  \n",
    "  times = np.array(ripples)\n",
    "  times[:,1] = times[:,1] + intervalo\n",
    "  return times / fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgMEJ1lIKGsp"
   },
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uQfZzidDKGsp"
   },
   "outputs": [],
   "source": [
    "def undersamplingIndexes(data) :\n",
    "    \"\"\"\n",
    "    Hace un undersampling de los datos\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Numpy Array (N x 8)\n",
    "        Numpy array con los datos\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    undersamplingIndexes : Numpy Array (N x 1)\n",
    "        Numpy array con los indices de os datos\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    indexes = undersamplingIndexes(solsIntervalo)\n",
    "    \"\"\"\n",
    "    ripples_unos = list()\n",
    "    ripples_zeros = list()\n",
    "\n",
    "    for i in range(0, len(data) - 1):\n",
    "        if (data[i]==1):\n",
    "            ripples_unos.append(i)\n",
    "        else:\n",
    "            ripples_zeros.append(i)\n",
    "\n",
    "    yes_ripple = np.array(ripples_unos)\n",
    "    non_ripple = np.array(np.random.choice(ripples_zeros, 7000000, replace = False))\n",
    "    undersamplingIndexes = np.concatenate([non_ripple, yes_ripple])\n",
    "    undersamplingIndexes = np.sort(undersamplingIndexes)\n",
    "    return undersamplingIndexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfJGboc8KGsq"
   },
   "source": [
    "# Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6X-yeNSVKGsq"
   },
   "outputs": [],
   "source": [
    "inter = 700\n",
    "porcen = 0.6\n",
    "zeros = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OfTD9DuKGsq"
   },
   "source": [
    "Obtener los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rtzr1v7iyOc9"
   },
   "outputs": [],
   "source": [
    "datapath = \"/content/Datos/Entrenamiento/Som2/figshare_16856137\"\n",
    "data_som2, fs_som2, session_name = load_data(datapath)\n",
    "ripples_tags_som2 = load_ripples_tags(datapath, fs_som2)\n",
    "signal_som2 = get_ripples_tags_as_signal(data_som2, ripples_tags_som2, fs_som2)\n",
    "som2_scaled = RobustScaler().fit_transform(data_som2)\n",
    "canal_som2 = som2_scaled[:, 0]\n",
    "\n",
    "datapath = \"/content/Datos/Entrenamiento/Amigo2/figshare_16847521\"\n",
    "data_am2, fs_am2, session_name = load_data(datapath)\n",
    "ripples_tags_am2 = load_ripples_tags(datapath, fs_am2)\n",
    "signal_am2 = get_ripples_tags_as_signal(data_am2, ripples_tags_am2, fs_am2)\n",
    "am2_scaled = RobustScaler().fit_transform(data_am2)\n",
    "canal_am2 = am2_scaled[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1nTnK8ZKGsr"
   },
   "source": [
    "Obtener datos de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tu1G25mqKGss"
   },
   "outputs": [],
   "source": [
    "datapath = \"/content/Datos/Validacion/Thy7/figshare_14960085\"\n",
    "data_thy7, fs_thy7, session_name = load_data(datapath)\n",
    "ripples_tags_thy7 = load_ripples_tags(datapath, fs_thy7)\n",
    "signal_thy7 = get_ripples_tags_as_signal(data_thy7, ripples_tags_thy7, fs_thy7)\n",
    "thy7_scaled = RobustScaler().fit_transform(data_thy7)\n",
    "canal_thy7 = thy7_scaled[:, 0]\n",
    "\n",
    "datapath = \"/content/Datos/Validacion/Dlx1/figshare_14959449\"\n",
    "data_dlx1, fs_dlx1, session_name = load_data(datapath)\n",
    "ripples_tags_dlx1 = load_ripples_tags(datapath, fs_dlx1)\n",
    "signal_dlx1 = get_ripples_tags_as_signal(data_dlx1, ripples_tags_dlx1, fs_dlx1)\n",
    "dlx1_scaled = RobustScaler().fit_transform(data_dlx1)\n",
    "canal_dlx1 = dlx1_scaled[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xBaeyQAKGss"
   },
   "source": [
    "Pasar las soluciones a intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6N3pmZl7p1BU"
   },
   "outputs": [],
   "source": [
    "solsIntervalo_som2 = solsToIntervals(signal_som2, inter, porcen)\n",
    "solsIntervalo_am2 = solsToIntervals(signal_am2, inter, porcen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fasAZLR3KGst"
   },
   "source": [
    "Obtener las caracteristicas de los intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOBKEW2zKGst"
   },
   "outputs": [],
   "source": [
    "diffs_som2 = getPendientes(canal_som2)\n",
    "pendientes_som2, amplitudes_som2, absampl_som2 = getCharacteristics(diffs_som2, canal_som2, inter)\n",
    "\n",
    "diffs_am2 = getPendientes(canal_am2)\n",
    "pendientes_am2, amplitudes_am2, absampl_am2 = getCharacteristics(diffs_am2, canal_am2, inter)\n",
    "\n",
    "diffs_thy7 = getPendientes(canal_thy7)\n",
    "pendientes_thy7, amplitudes_thy7, absampl_thy7 = getCharacteristics(diffs_thy7, canal_thy7, inter)\n",
    "\n",
    "diffs_dlx1 = getPendientes(canal_dlx1)\n",
    "pendientes_dlx1, amplitudes_dlx1, absampl_dlx1 = getCharacteristics(diffs_dlx1, canal_dlx1, inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CefG2QQ5KGsu"
   },
   "source": [
    "Combinar datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "molGQRkPKGsu"
   },
   "outputs": [],
   "source": [
    "pendientes = np.concatenate((pendientes_som2, pendientes_am2))\n",
    "amplitudes = np.concatenate((amplitudes_som2, amplitudes_am2))\n",
    "absampl = np.concatenate((absampl_som2, absampl_am2))\n",
    "solsIntervalo = np.concatenate((solsIntervalo_som2, solsIntervalo_am2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stOZZvcVKGsu"
   },
   "source": [
    "Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvz1y-7hKGsu"
   },
   "outputs": [],
   "source": [
    "indexes = undersamplingIndexes(solsIntervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqokmnnOKGsv"
   },
   "outputs": [],
   "source": [
    "pendientes_under = pendientes[indexes]\n",
    "amplitudes_under = amplitudes[indexes]\n",
    "absampl_under = absampl[indexes]\n",
    "solsIntervalo_under = solsIntervalo[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tITPNR9lKGsv"
   },
   "source": [
    "Obtener los datos de entrenamiento juntado las caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWzxPZojimgZ"
   },
   "outputs": [],
   "source": [
    "train = getDataSet(pendientes_under, amplitudes_under, absampl_under)\n",
    "\n",
    "val_thy7 = getDataSet(pendientes_thy7, amplitudes_thy7, absampl_thy7)\n",
    "\n",
    "val_dlx1 = getDataSet(pendientes_dlx1, amplitudes_dlx1, absampl_dlx1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye-ArBczKGsv"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZ2UlXEiKGsw"
   },
   "source": [
    "Entrenar clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKA63rrx_1on"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "boostClassifier = XGBClassifier()\n",
    "boostClassifier.fit(train, solsIntervalo_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awF4zd3EKGsx"
   },
   "source": [
    "Predecir soluciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axdF0_sZKGsx"
   },
   "outputs": [],
   "source": [
    "boostPredict_thy7 = boostClassifier.predict(val_thy7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPpqlaxWKGsy"
   },
   "source": [
    "Pasar predicciones a tiempos bien marcados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0KEy0KtKGsy"
   },
   "outputs": [],
   "source": [
    "tiemposBoostPredict_thy7 = toTimes(boostPredict_thy7, fs_thy7, zeros, inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgbP7IGoKGsy"
   },
   "source": [
    "Calculo F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tioD3VkKGsy"
   },
   "outputs": [],
   "source": [
    "get_score(ripples_tags_thy7, tiemposBoostPredict_thy7, threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5hwyFX9KGsz"
   },
   "source": [
    "Igual para datos de DIx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIkBJb0HKGsz"
   },
   "outputs": [],
   "source": [
    "boostPredict_dlx1 = boostClassifier.predict(val_dlx1)\n",
    "tiemposBoostPredict_dlx1 = toTimes(boostPredict_dlx1, fs_dlx1, zeros, inter)\n",
    "get_score(ripples_tags_dlx1, tiemposBoostPredict_dlx1, threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoXiaFmZKGsz"
   },
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLu6UbsYKGs0"
   },
   "outputs": [],
   "source": [
    "datapath = \"/content/Datos/Test/Test1/figshare_16856182\"\n",
    "data_t1, fs_t1, session_name_t1 = load_data(datapath)\n",
    "t1_scaled = RobustScaler().fit_transform(data_t1)\n",
    "canal_t1 = t1_scaled[:, 0]\n",
    "\n",
    "datapath = \"/content/Datos/Test/Test2/figshare_16856248\"\n",
    "data_t2, fs_t2, session_name_t2 = load_data(datapath)\n",
    "t2_scaled = RobustScaler().fit_transform(data_t2)\n",
    "canal_t2 = t2_scaled[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSKlx7HnKGs0"
   },
   "outputs": [],
   "source": [
    "diffs_t1 = getPendientes(canal_t1)\n",
    "pendientes_t1, amplitudes_t1, absampl_t1 = getCharacteristics(diffs_t1, canal_t1, inter)\n",
    "\n",
    "diffs_t2 = getPendientes(canal_t2)\n",
    "pendientes_t2, amplitudes_t2, absampl_t2 = getCharacteristics(diffs_t2, canal_t2, inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uudgLjh4KGs0"
   },
   "outputs": [],
   "source": [
    "test_t1 = getDataSet(pendientes_t1, amplitudes_t1, absampl_t1)\n",
    "\n",
    "test_t2 = getDataSet(pendientes_t2, amplitudes_t2, absampl_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "galpr__sKGs0"
   },
   "outputs": [],
   "source": [
    "boostPredict_t1 = boostClassifier.predict(test_t1)\n",
    "\n",
    "boostPredict_t2 = boostClassifier.predict(test_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnKL6ZGSKGs1"
   },
   "outputs": [],
   "source": [
    "tiemposBoostPredict_t1 = toTimes(boostPredict_t1, fs_t1, zeros, inter)\n",
    "\n",
    "tiemposBoostPredict_t2 = toTimes(boostPredict_t2, fs_t2, zeros, inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3dvoASyKGs1"
   },
   "outputs": [],
   "source": [
    "save_path_t1 = '/content/Resultados/Test1'\n",
    "\n",
    "save_path_t2 = '/content/Resultados/Test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5xdmwSRKGs1"
   },
   "outputs": [],
   "source": [
    "write_results (save_path_t1, session_name_t1, 6, tiemposBoostPredict_t1)\n",
    "\n",
    "write_results (save_path_t2, session_name_t2, 6, tiemposBoostPredict_t2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nq6ZCfZxKGsc"
   ],
   "name": "Colab.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "af35e99f511c6772fb57fbf4970e0137b8d7f416e3d9d8133f4839f3a2eceed2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
