{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bcg_auxiliary import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función getPendientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oEe_dKeAyVAG"
   },
   "outputs": [],
   "source": [
    "def getPendientes(canal):\n",
    "\t\"\"\"\n",
    "\tObtiene las diferencias de amplitud entre un punto y su vecino anterior y posterior\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tcanal : Numpy array (N x 1)\n",
    "\t\tNumpy array que contiene las amplitudes de un canal\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tdiffs : Numpy array (N-1 x 1)\n",
    "\t\tNumpy array  que contiene las pendientes de los puntos repsecto a sus dos vecinos\n",
    "\n",
    "\tExample\n",
    "\t-------\n",
    "\tdiffs = getPendientes(canal0)\n",
    "\t\"\"\"\n",
    "\n",
    "\tdiffs = list()\n",
    "\tfor i in range(0, len(canal) - 1):\n",
    "\t\tdiffs.append(canal[i+1] - canal[i])\n",
    "\treturn np.array(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función getCharacteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TQzdo5nmy6yg"
   },
   "outputs": [],
   "source": [
    "def getCharacteristics(differences, amplitudes, intervalo=400):\n",
    "\t\"\"\"\n",
    "\tObtiene las caracteristicas de un ripple\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdifferences : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene las pendientes de los puntos \n",
    "\t\trespecto a sus dos vecinos\n",
    "\tamplitudes :  Numpy Array (N x 1)\n",
    "\t\tNumpy array que contiene las amplitudes de un canal\n",
    "\tintervalo : int\n",
    "\t\tTamaño de los intervalos en los que se dividira la senal\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tsumsPend : Numpy Array (N - intervalo x 1)\n",
    "\t\tNumpy array  que contiene la suma de las pendientes de los \n",
    "\t\tpuntos dentro de un intervalo\n",
    "\tsumsAmpl : Numpy Array (N - intervalo x 1)\n",
    "\t\tNumpy array  que contiene la suma de las amplitudes de los \n",
    "\t\tpuntos dentro de un intervalo\n",
    "\tsumsAbsAmpl\t: Numpy Array (N - intervalo x 1)\n",
    "\t\tNumpy array con la suma de las amplitudes en valor absoluto\n",
    "\t\tde los puntos dentro de un intervalo\n",
    "\tExample\n",
    "\t-------\n",
    "\tpendientes, amplitudes, absampl = getCharacteristics(diffs, canal, 200)\n",
    "\t\"\"\"\n",
    "\n",
    "\tabsolutes = np.abs(differences)\n",
    "\tabsamp = np.abs(amplitudes)\n",
    "\tsumsPend = list()\n",
    "\tsumsAmpl = list()\n",
    "\tsumsAbsAmpl = list()\n",
    "\n",
    "\tsumsPendInter = np.sum(absolutes[:intervalo])\n",
    "\tsumsPend.append(sumsPendInter)\n",
    "\tsumsAmplInter = np.sum(amplitudes[:intervalo])\n",
    "\tsumsAmpl.append(sumsAmplInter)\n",
    "\tsumsAbsAmplInter = np.sum(absamp[:intervalo])\n",
    "\tsumsAbsAmpl.append(sumsAbsAmplInter)\n",
    "\n",
    "\tfor i in range(1, len(absolutes) - intervalo):\n",
    "\t\tsumsPendInter = sumsPendInter + absolutes[i+intervalo] - absolutes[i-1]\n",
    "\t\tsumsPend.append(sumsPendInter)\n",
    "\t\tsumsAmplInter = sumsAmplInter + amplitudes[i+intervalo] - amplitudes[i-1]\n",
    "\t\tsumsAmpl.append(sumsAmplInter)\n",
    "\t\tsumsAbsAmplInter = sumsAbsAmplInter + absamp[i+intervalo] - absamp[i-1]\n",
    "\t\tsumsAbsAmpl.append(sumsAbsAmplInter)\n",
    "\n",
    "\treturn np.array(sumsPend), np.array(sumsAmpl), np.array(sumsAbsAmpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función solsToIntervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RbYK39-a4TAC"
   },
   "outputs": [],
   "source": [
    "def solsToIntervals(solutions, intervalo=400, porcentaje=0.5):\n",
    "  \"\"\"\n",
    "\tPasa el array de soluciones a intervalos\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tsolutions : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene si un punto es ripple o no\n",
    "\tintervalo : int\n",
    "\t\tTamaño de los intervalos en los que esta dividida la senal\n",
    "\tporcentaje : int\n",
    "\t\tPorcentaje del numero de 1s que debe haber en un intervalo\n",
    "\t\tpara que se considere ripple\n",
    "\t\n",
    "\tReturns\n",
    "\t-------\n",
    "\tsumsSols : Numpy Array (N - intervalo - 1 x 1)\n",
    "\t\tNumpy array  que contiene  si un intervalo\n",
    "\t\tes ripple o no\t\n",
    "\n",
    "\tExample\n",
    "\t-------\n",
    "\tsolsIntervalo = solsToIntervals(signal)\n",
    "\n",
    "\t\"\"\"\n",
    "  \n",
    "  sumsSols = list()\n",
    "\n",
    "  sumsSolsInter = np.sum(solutions[:intervalo])\n",
    "  sumsSols.append(sumsSolsInter)\n",
    "  umbral = int(porcentaje * intervalo)\n",
    "  \n",
    "  for i in range(1, len(solutions) - intervalo - 1):\n",
    "    sumsSolsInter = sumsSolsInter + solutions[i+intervalo] - solutions[i-1]\n",
    "    sol = 1 if sumsSolsInter >= umbral else 0\n",
    "    sumsSols.append(sol)\n",
    "  \n",
    "  return np.array(sumsSols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función getDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4To7O_Gc9t4n"
   },
   "outputs": [],
   "source": [
    "def getDataSet(pendientes, amplitudes, abs_amplitudes):\n",
    "\t\"\"\"\n",
    "\tUne las caracteristicas del ripple en un mismo array\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tpendientes : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene la suma de las pendientes de los \n",
    "\t\tpuntos dentro de un intervalo\n",
    "\tamplitudes : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene la suma de las amplitudes de los \n",
    "\t\tpuntos dentro de un intervalo\n",
    "\tabs_amplitudes : Numpy Array (N x 1)\n",
    "\t\tNumpy array  que contiene la suma de las amplitudes en\n",
    "\t\tvalor absoluto de los puntos dentro de un intervalo\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tdataset : Numpy Array (N x 3)\n",
    "\t\tNumpy array  que contiene los array de \n",
    "\t\tpendientes y amplitudes unidos\n",
    "\n",
    "\tExample\n",
    "\t-------\n",
    "\ttrain = getDataSet(pendientes, amplitudes, absampl)\n",
    "\t\"\"\"\n",
    "\tdataset = np.zeros([len(pendientes), 3])\n",
    "\tdataset[:, 0] = pendientes\n",
    "\tdataset[:, 1] = amplitudes\n",
    "\tdataset[:, 2] = abs_amplitudes\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función toTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UPku3hc2TrHb"
   },
   "outputs": [],
   "source": [
    "def toTimes(prediction, fs, zeros=400, intervalo=400) :\n",
    "  \"\"\"\n",
    "  Pasa la prediccion de los intervalos a intervalos completos de tiempo\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  prediction : Numpy Array (N x 1)\n",
    "    Numpy array que indica si un intervalo es ripple o no\n",
    "  fs : int\n",
    "    Frecuencia de sampleo\n",
    "  zeros : int\n",
    "    Numero de ceros que tiene que pasar para que se considere\n",
    "    que el ripple ha terminado\n",
    "  intervalo : int\n",
    "    Tamaño de los intervalos en los que esta dividida la senal\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  times : Numpy Array (N x 1)\n",
    "    Numpy array con las predicciones pasadas a tiempos\n",
    "\n",
    "  Example\n",
    "  -------\n",
    "  tiemposBoostPredict = toTimes(boostPredict, fs, zeros=700, intervalo=400)\n",
    "  \"\"\"\n",
    "  insideRipple = False\n",
    "  ripples = list()\n",
    "\n",
    "  start = 0\n",
    "  end = 0\n",
    "  zerosCount = 0\n",
    "  zerosUmbral = zeros\n",
    "\n",
    "  for i, n in enumerate(prediction):\n",
    "    if (n == 1):\n",
    "      if (not insideRipple):\n",
    "        insideRipple = True\n",
    "        start = i\n",
    "      zerosCount = 0\n",
    "    elif (n == 0 and insideRipple):\n",
    "      zerosCount += 1\n",
    "      if (zerosCount >= zerosUmbral):\n",
    "        end =  i - zerosUmbral\n",
    "        ripples.append(np.array([start, end]))\n",
    "        insideRipple = False\n",
    "        start, end = 0, 0\n",
    "  \n",
    "  times = np.array(ripples)\n",
    "  times[:,1] = times[:,1] + intervalo\n",
    "  return times / fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersamplingIndexes(data) :\n",
    "    \"\"\"\n",
    "    Hace un undersampling de los datos\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Numpy Array (N x 8)\n",
    "        Numpy array con los datos\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    undersamplingIndexes : Numpy Array (N x 1)\n",
    "        Numpy array con los indices de os datos\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    indexes = undersamplingIndexes(solsIntervalo)\n",
    "    \"\"\"\n",
    "    ripples_unos = list()\n",
    "    ripples_zeros = list()\n",
    "\n",
    "    for i in range(0, len(data) - 1):\n",
    "        if (data[i]==1):\n",
    "            ripples_unos.append(i)\n",
    "        else:\n",
    "            ripples_zeros.append(i)\n",
    "\n",
    "    yes_ripple = np.array(ripples_unos)\n",
    "    non_ripple = np.array(np.random.choice(ripples_zeros, 7000000, replace = False))\n",
    "    undersamplingIndexes = np.concatenate([non_ripple, yes_ripple])\n",
    "    undersamplingIndexes = np.sort(undersamplingIndexes)\n",
    "    return undersamplingIndexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = 700\n",
    "porcen = 0.6\n",
    "zeros = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rtzr1v7iyOc9"
   },
   "outputs": [],
   "source": [
    "datapath = \"./Datos/Entrenamiento/Som2\"\n",
    "data_som2, fs_som2, session_name = load_data(datapath)\n",
    "ripples_tags_som2 = load_ripples_tags(datapath, fs_som2)\n",
    "signal_som2 = get_ripples_tags_as_signal(data_som2, ripples_tags_som2, fs_som2)\n",
    "som2_scaled = RobustScaler().fit_transform(data_som2)\n",
    "canal_som2 = som2_scaled[:, 0]\n",
    "\n",
    "datapath = \"./Datos/Entrenamiento/Amigo2\"\n",
    "data_am2, fs_am2, session_name = load_data(datapath)\n",
    "ripples_tags_am2 = load_ripples_tags(datapath, fs_am2)\n",
    "signal_am2 = get_ripples_tags_as_signal(data_am2, ripples_tags_am2, fs_am2)\n",
    "am2_scaled = RobustScaler().fit_transform(data_am2)\n",
    "canal_am2 = am2_scaled[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener datos de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"./Datos/Validación/Thy7\"\n",
    "data_thy7, fs_thy7, session_name = load_data(datapath)\n",
    "ripples_tags_thy7 = load_ripples_tags(datapath, fs_thy7)\n",
    "signal_thy7 = get_ripples_tags_as_signal(data_thy7, ripples_tags_thy7, fs_thy7)\n",
    "thy7_scaled = RobustScaler().fit_transform(data_thy7)\n",
    "canal_thy7 = thy7_scaled[:, 0]\n",
    "\n",
    "datapath = \"./Datos/Validación/Dlx1\"\n",
    "data_dlx1, fs_dlx1, session_name = load_data(datapath)\n",
    "ripples_tags_dlx1 = load_ripples_tags(datapath, fs_dlx1)\n",
    "signal_dlx1 = get_ripples_tags_as_signal(data_dlx1, ripples_tags_dlx1, fs_dlx1)\n",
    "dlx1_scaled = RobustScaler().fit_transform(data_dlx1)\n",
    "canal_dlx1 = dlx1_scaled[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasar las soluciones a intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6N3pmZl7p1BU"
   },
   "outputs": [],
   "source": [
    "solsIntervalo_som2 = solsToIntervals(signal_som2, inter, porcen)\n",
    "solsIntervalo_am2 = solsToIntervals(signal_am2, inter, porcen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener las caracteristicas de los intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs_som2 = getPendientes(canal_som2)\n",
    "pendientes_som2, amplitudes_som2, absampl_som2 = getCharacteristics(diffs_som2, canal_som2, inter)\n",
    "\n",
    "diffs_am2 = getPendientes(canal_am2)\n",
    "pendientes_am2, amplitudes_am2, absampl_am2 = getCharacteristics(diffs_am2, canal_am2, inter)\n",
    "\n",
    "diffs_thy7 = getPendientes(canal_thy7)\n",
    "pendientes_thy7, amplitudes_thy7, absampl_thy7 = getCharacteristics(diffs_thy7, canal_thy7, inter)\n",
    "\n",
    "diffs_dlx1 = getPendientes(canal_dlx1)\n",
    "pendientes_dlx1, amplitudes_dlx1, absampl_dlx1 = getCharacteristics(diffs_dlx1, canal_dlx1, inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinar datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendientes = np.concatenate((pendientes_som2, pendientes_am2))\n",
    "amplitudes = np.concatenate((amplitudes_som2, amplitudes_am2))\n",
    "absampl = np.concatenate((absampl_som2, absampl_am2))\n",
    "solsIntervalo = np.concatenate((solsIntervalo_som2, solsIntervalo_am2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = undersamplingIndexes(solsIntervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendientes_under = pendientes[indexes]\n",
    "amplitudes_under = amplitudes[indexes]\n",
    "absampl_under = absampl[indexes]\n",
    "solsIntervalo_under = solsIntervalo[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener los datos de entrenamiento juntado las caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YWzxPZojimgZ"
   },
   "outputs": [],
   "source": [
    "train = getDataSet(pendientes_under, amplitudes_under, absampl_under)\n",
    "\n",
    "val_thy7 = getDataSet(pendientes_thy7, amplitudes_thy7, absampl_thy7)\n",
    "\n",
    "val_dlx1 = getDataSet(pendientes_dlx1, amplitudes_dlx1, absampl_dlx1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HKA63rrx_1on"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elisa\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:50:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='approx', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "boostClassifier = XGBClassifier()\n",
    "boostClassifier.fit(train, solsIntervalo_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecir soluciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostPredict_thy7 = boostClassifier.predict(val_thy7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasar predicciones a tiempos bien marcados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiemposBoostPredict_thy7 = toTimes(boostPredict_thy7, fs_thy7, zeros, inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6991758241758241, 0.4783834586466165, 0.5680803571428571)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(ripples_tags_thy7, tiemposBoostPredict_thy7, threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual para datos de DIx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35, 0.0995260663507109, 0.15498154981549814)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boostPredict_dlx1 = boostClassifier.predict(val_dlx1)\n",
    "tiemposBoostPredict_dlx1 = toTimes(boostPredict_dlx1, fs_dlx1, zeros, inter)\n",
    "get_score(ripples_tags_dlx1, tiemposBoostPredict_dlx1, threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"./Datos/Test/Test1\"\n",
    "data_t1, fs_t1, session_name_t1 = load_data(datapath)\n",
    "t1_scaled = RobustScaler().fit_transform(data_t1)\n",
    "canal_t1 = t1_scaled[:, 0]\n",
    "\n",
    "datapath = \"./Datos/Test/Test2\"\n",
    "data_t2, fs_t2, session_name_t2 = load_data(datapath)\n",
    "t2_scaled = RobustScaler().fit_transform(data_t2)\n",
    "canal_t2 = t2_scaled[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs_t1 = getPendientes(canal_t1)\n",
    "pendientes_t1, amplitudes_t1, absampl_t1 = getCharacteristics(diffs_t1, canal_t1, inter)\n",
    "\n",
    "diffs_t2 = getPendientes(canal_t2)\n",
    "pendientes_t2, amplitudes_t2, absampl_t2 = getCharacteristics(diffs_t2, canal_t2, inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t1 = getDataSet(pendientes_t1, amplitudes_t1, absampl_t1)\n",
    "\n",
    "test_t2 = getDataSet(pendientes_t2, amplitudes_t2, absampl_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostPredict_t1 = boostClassifier.predict(test_t1)\n",
    "\n",
    "boostPredict_t2 = boostClassifier.predict(test_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiemposBoostPredict_t1 = toTimes(boostPredict_t1, fs_t1, zeros, inter)\n",
    "\n",
    "tiemposBoostPredict_t2 = toTimes(boostPredict_t2, fs_t2, zeros, inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_t1 = './Resultados/Test1'\n",
    "\n",
    "save_path_t2 = './Resultados/Test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results (save_path_t1, session_name_t1, 6, tiemposBoostPredict_t1)\n",
    "\n",
    "write_results (save_path_t2, session_name_t2, 6, tiemposBoostPredict_t2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pruebas.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "af35e99f511c6772fb57fbf4970e0137b8d7f416e3d9d8133f4839f3a2eceed2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
